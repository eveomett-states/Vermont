{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vermont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data retrieved 05/23/24:\n",
    "https://redistrictingdatahub.org/dataset/vermont-block-pl-94171-2020-by-table/\n",
    "\n",
    "https://redistrictingdatahub.org/dataset/vest-2020-vermont-precinct-boundaries-and-election-results-shapefile/\n",
    "https://redistrictingdatahub.org/dataset/vest-2018-vermont-precinct-and-election-results/\n",
    "https://redistrictingdatahub.org/dataset/vest-2016-vermont-precinct-and-election-results/\n",
    "\n",
    "https://redistrictingdatahub.org/dataset/2022-vermont-senate-districts-approved-plan/\n",
    "https://redistrictingdatahub.org/dataset/2022-vermont-house-of-representatives-districts-approved-plan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import maup\n",
    "import time\n",
    "from maup import smart_repair\n",
    "from gerrychain import Graph\n",
    "\n",
    "maup.progress.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = Vermont\n",
    "state_ab = \"vt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "1. Download all the data in directory \"vt_data\"\n",
    "2. Extract them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = state_ab + \"_data/\"\n",
    "population1_data = \"./{}{}_pl2020_b/{}_pl2020_p1_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "population2_data = \"./{}{}_pl2020_b/{}_pl2020_p2_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "vap_data =  \"./{}{}_pl2020_b/{}_pl2020_p4_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest20_data = \"./{}{}_vest_20/{}_vest_20.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest18_data = \"./{}{}_vest_18/{}_vest_18.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest16_data = \"./{}{}_vest_16/{}_vest_16.shp\".format(data_folder, state_ab, state_ab)\n",
    "send_data = \"./{}{}_sldu_adopted_2022/Districts 2022-04-05.shp\".format(data_folder, state_ab)\n",
    "hdist_data = \"./{}{}_sldl_adopted_2022/Districts 2022-04-05.shp\".format(data_folder, state_ab)\n",
    "county_data = \"./{}{}_cvap_2022_cnty/{}_cvap_2022_cnty.shp\".format(data_folder, state_ab, state_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_smart_repair(df, min_rook_length = None, snap_precision = 10):\n",
    "    # change it to the UTM it needs for smart_repair\n",
    "    df = df.to_crs(df.estimate_utm_crs())\n",
    "    df = smart_repair(df, min_rook_length = min_rook_length)\n",
    "\n",
    "    if maup.doctor(df) == False:\n",
    "        raise Exception('maup.doctor failed')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_district(dist_df, dist_name, election_df, col_name):\n",
    "    election_df = election_df.to_crs(election_df.estimate_utm_crs())\n",
    "    dist_df = dist_df.to_crs(dist_df.estimate_utm_crs())\n",
    "    # check if it needs to be smart_repair\n",
    "    if maup.doctor(dist_df) != True:\n",
    "        dist_df = do_smart_repair(dist_df)\n",
    "\n",
    "    # assign the pricincts\n",
    "    precincts_to_district_assignment = maup.assign(election_df.geometry, dist_df.geometry)\n",
    "    election_df[dist_name] = precincts_to_district_assignment\n",
    "    for precinct_index in range(len(election_df)):\n",
    "        election_df.at[precinct_index, dist_name] = dist_df.at[election_df.at[precinct_index, dist_name], col_name]\n",
    "\n",
    "    return election_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(original, year):\n",
    "    party = original[6]\n",
    "    if party == 'R' or party == 'D':\n",
    "        return original[3:6] + year + original[6]\n",
    "    else:\n",
    "        return original[3:6] + year + 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_col = ['TOTPOP', 'HISP', 'NH_WHITE', 'NH_BLACK', 'NH_AMIN', 'NH_ASIAN', 'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'H_WHITE', 'H_BLACK', 'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE', 'VAP', 'HVAP', 'WVAP', 'BVAP', 'AMINVAP', 'ASIANVAP', 'NHPIVAP', 'OTHERVAP', '2MOREVAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_population(population, df):\n",
    "    pop_check = pd.DataFrame({\n",
    "        'pop_col': pop_col,\n",
    "        'population_df': population[pop_col].sum(), \n",
    "        'vest_base': df[pop_col].sum(),\n",
    "        'equal': [x == y for x, y in zip(population[pop_col].sum(), df[pop_col].sum())]\n",
    "    })\n",
    "    if pop_check['equal'].mean() < 1:\n",
    "        print(pop_check)\n",
    "        raise Exception(\"population doesn't agree\")\n",
    "\n",
    "    else:\n",
    "        print(\"population agrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vest(vest, df, year, population, start_col, snap_precision = 10):\n",
    "    df = df.to_crs(df.estimate_utm_crs())\n",
    "    vest = vest.to_crs(vest.estimate_utm_crs())\n",
    "    population = population.to_crs(population.estimate_utm_crs())\n",
    "    df_crs = df.crs\n",
    "    vest_crs = vest.crs\n",
    "    \n",
    "     # check if it needs to be smart_repair\n",
    "    if maup.doctor(vest) != True:\n",
    "        vest = do_smart_repair(vest, snap_precision = snap_precision)\n",
    "    \n",
    "    # rename the columns\n",
    "    original_col = vest.columns[start_col:-1]\n",
    "    new_col = [rename(i, year) for i in original_col]\n",
    "    rename_dict = dict(zip(original_col, new_col))\n",
    "    vest = vest.rename(columns=rename_dict)\n",
    "    vest = vest.groupby(level=0, axis=1).sum() # combine all the other party's vote into columns with sufix \"O\"\n",
    "    col_name = list(set(new_col))\n",
    "    col_name.sort()\n",
    "    \n",
    "    # make the blocks from precincts by weight\n",
    "    vest = gpd.GeoDataFrame(vest, crs=vest_crs)\n",
    "    election_in_block = population[[\"VAP\", 'geometry']] # population_df is in block scale\n",
    "    blocks_to_precincts_assignment = maup.assign(election_in_block.geometry, vest.geometry)\n",
    "    weights = election_in_block[\"VAP\"] / blocks_to_precincts_assignment.map(election_in_block[\"VAP\"].groupby(blocks_to_precincts_assignment).sum())\n",
    "    weights = weights.fillna(0)\n",
    "    prorated = maup.prorate(blocks_to_precincts_assignment, vest[col_name], weights)\n",
    "    election_in_block[col_name] = prorated\n",
    "    \n",
    "    # assign blocks to precincts\n",
    "    election_in_block = gpd.GeoDataFrame(election_in_block, crs=vest_crs)\n",
    "    df = gpd.GeoDataFrame(df, crs=df_crs)\n",
    "    block_to_pricinct_assginment = maup.assign(election_in_block.geometry, df.geometry)\n",
    "    df[col_name] = election_in_block[col_name].groupby(block_to_pricinct_assginment).sum()\n",
    "    df = df.groupby(level=0, axis=1).sum()\n",
    "    df = gpd.GeoDataFrame(df, crs = df_crs)\n",
    "    # check if population agrees\n",
    "    check_population(population, df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vest_base(vest, start_col, year, county = None, min_rook_length = None, snap_precision = 10):\n",
    "    vest = vest.to_crs(vest.estimate_utm_crs())\n",
    "    vest_crs = vest.crs\n",
    "    original_col = vest.columns[start_col:-1]\n",
    "    new_col = [rename(i, year) for i in original_col]\n",
    "    rename_dict = dict(zip(original_col, new_col))\n",
    "    vest = vest.rename(columns=rename_dict)\n",
    "    vest = vest.groupby(level=0, axis=1).sum()\n",
    "    vest = gpd.GeoDataFrame(vest, crs=vest_crs)\n",
    "\n",
    "    if county is not None:\n",
    "        county = county.to_crs(county.estimate_utm_crs())\n",
    "        vest = smart_repair(vest, nest_within_regions = county, min_rook_length = min_rook_length, snap_precision = snap_precision) # nest precincts within counties\n",
    "\n",
    "    else:\n",
    "        vest = smart_repair(vest, min_rook_length = min_rook_length, snap_precision = snap_precision) \n",
    "    \n",
    "    return vest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_small_boundary_lengths(vest_base):\n",
    "    import copy\n",
    "    vest_base = vest_base.to_crs(vest_base.estimate_utm_crs())\n",
    "\n",
    "    boundaries = copy.deepcopy(vest_base)\n",
    "    boundaries[\"geometry\"] = boundaries.geometry.boundary  # get boundaries\n",
    "    neighbors = gpd.sjoin(boundaries, vest_base, predicate=\"intersects\") # find boundaries that intersect\n",
    "    neighbors = neighbors[neighbors.index != neighbors.index_right] # remove boundaries of a region with itself\n",
    "\n",
    "    # compute shared border length using intersection\n",
    "    borders = list(neighbors.apply(\n",
    "        lambda row: row.geometry.intersection(vest_base.loc[row.index_right, \"geometry\"]).length, axis=1\n",
    "    ))\n",
    "\n",
    "    borders.sort()\n",
    "    \n",
    "    return borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "population1_df = gpd.read_file(population1_data)\n",
    "population2_df = gpd.read_file(population2_data)\n",
    "vap_df = gpd.read_file(vap_data)\n",
    "county_df = gpd.read_file(county_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "population2_df = population2_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])\n",
    "vap_df = vap_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.merge(population1_df, population2_df, on='GEOID20')\n",
    "population_df = pd.merge(population_df, vap_df, on='GEOID20')\n",
    "population_df = population_df.to_crs(population_df.estimate_utm_crs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 24611/24611 [00:11<00:00, 2109.79it/s]\n"
     ]
    }
   ],
   "source": [
    "maup.doctor(population_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df['H_WHITE'] = population_df.apply(lambda t: t['P0010003'] - t['P0020005'], 1)\n",
    "population_df['H_BLACK'] = population_df.apply(lambda t: t['P0010004'] - t['P0020006'], 1)\n",
    "population_df['H_AMIN'] = population_df.apply(lambda t: t['P0010005'] - t['P0020007'], 1)\n",
    "population_df['H_ASIAN'] = population_df.apply(lambda t: t['P0010006'] - t['P0020008'], 1)\n",
    "population_df['H_NHPI'] = population_df.apply(lambda t: t['P0010007'] - t['P0020009'], 1)\n",
    "population_df['H_OTHER'] = population_df.apply(lambda t: t['P0010008'] - t['P0020010'], 1)\n",
    "population_df['H_2MORE'] = population_df.apply(lambda t: t['P0010009'] - t['P0020011'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'P0020001': 'TOTPOP', 'P0020002': 'HISP', 'P0020005': 'NH_WHITE', 'P0020006': 'NH_BLACK', 'P0020007': 'NH_AMIN',\n",
    "                    'P0020008': 'NH_ASIAN', 'P0020009': 'NH_NHPI', 'P0020010': 'NH_OTHER', 'P0020011': 'NH_2MORE',\n",
    "                    'P0040001': 'VAP', 'P0040002': 'HVAP', 'P0040005': 'WVAP', 'P0040006': 'BVAP', 'P0040007': 'AMINVAP',\n",
    "                                        'P0040008': 'ASIANVAP', 'P0040009': 'NHPIVAP', 'P0040010': 'OTHERVAP', 'P0040011': '2MOREVAP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.rename(columns=rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = county_df.to_crs(county_df.estimate_utm_crs())\n",
    "maup.doctor(county_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the vest 20 data\n",
    "\n",
    "Now using it as a \"base pricinct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if vest20 can be used as base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest20 = gpd.read_file(vest20_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest20.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_col = 3\n",
    "vest_base_data = vest20\n",
    "year = '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base = add_vest_base(vest_base_data, start_col, year, county = county_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = check_small_boundary_lengths(vest_base)\n",
    "print(borders[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base = do_smart_repair(vest_base, min_rook_length = 30.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maup.doctor(vest_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vap and population have the same GEOID20\n",
    "blocks_to_precincts_assignment = maup.assign(population_df.geometry, vest_base.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base[pop_col] = population_df[pop_col].groupby(blocks_to_precincts_assignment).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = gpd.GeoDataFrame(vest_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if population agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_population(population_df, vest_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more vest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest18 = gpd.read_file(vest18_data)\n",
    "vest16 = gpd.read_file(vest16_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest16.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_vest(vest18, election_df, '18', population_df, start_col)\n",
    "election_df = add_vest(vest16, election_df, '16', population_df, start_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add the district data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send = gpd.read_file(send_data)\n",
    "send = send.to_crs(send.estimate_utm_crs())\n",
    "hdist = gpd.read_file(hdist_data)\n",
    "hdist = hdist.to_crs(hdist.estimate_utm_crs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_district(send, \"SEND\", election_df, \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_district(hdist, \"HDIST\", election_df, \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maup.doctor(election_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the base precinct year after the precinct information column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = {}\n",
    "if 'COUNTYFP' + year not in election_df.columns:\n",
    "    base_columns = {\n",
    "        'COUNTYFP':'COUNTYFP'+year,\n",
    "        'STATEFP':'STATEFP'+year,\n",
    "        'NAME':'NAME'+year} \n",
    "election_df.rename(columns=base_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns\n",
    "fixed_columns = [\n",
    "    'COUNTYFP'+year,\n",
    "    'STATEFP'+year,\n",
    "    'NAME'+year,\n",
    "    'SEND',\n",
    "    'HDIST',\n",
    "    'TOTPOP',\n",
    "    'NH_2MORE',\n",
    "    'NH_AMIN',\n",
    "    'NH_ASIAN',\n",
    "    'NH_BLACK',\n",
    "    'NH_NHPI',\n",
    "    'NH_OTHER',\n",
    "    'NH_WHITE',\n",
    "    'HISP',\n",
    "    'H_AMIN',\n",
    "    'H_ASIAN',\n",
    "    'H_BLACK',\n",
    "    'H_NHPI',\n",
    "    'H_OTHER',\n",
    "    'H_WHITE',\n",
    "    'H_2MORE',\n",
    "    'VAP',\n",
    "    'HVAP',\n",
    "    'WVAP',\n",
    "    'BVAP',\n",
    "    'AMINVAP',\n",
    "    'ASIANVAP',\n",
    "    'NHPIVAP',\n",
    "    'OTHERVAP',\n",
    "    '2MOREVAP']\n",
    "\n",
    "election_columns = [col for col in election_df.columns if col not in fixed_columns]\n",
    "final_col = fixed_columns + election_columns\n",
    "election_df = election_df[final_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# store the result in directory \"il\"\n",
    "directory = \"./{}\".format(state_ab)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "shapefile_path = \"./{}/{}.shp\".format(state_ab, state_ab)\n",
    "geojson_path = './{}/{}.geojson'.format(state_ab, state_ab)\n",
    "json_path = \"./{}.json\".format(state_ab, state_ab)\n",
    "\n",
    "# Check if the shapefile or geojson file already exists\n",
    "if os.path.exists(shapefile_path):\n",
    "    os.remove(shapefile_path)\n",
    "if os.path.exists(geojson_path):\n",
    "    os.remove(geojson_path)\n",
    "\n",
    "election_df.to_file(shapefile_path)\n",
    "election_df.to_file(geojson_path, driver='GeoJSON')\n",
    "\n",
    "# Only do once to build json and read from file when generating ensembles\n",
    "graph = Graph.from_file(shapefile_path, ignore_errors=True)\n",
    "graph.to_json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = \"./{}/{}.shp\".format(state_ab, state_ab)\n",
    "shape=gpd.read_file(shapefile_path)\n",
    "shape.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gerry",
   "language": "python",
   "name": "gerry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
